{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4187026d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 匯入資料\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.datasets import mnist\n",
    "from keras import models \n",
    "from keras import layers\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "datasetTrain = pd.read_csv('adult.data.csv')\n",
    "datasetTest = pd.read_csv('adult.test.csv')\n",
    "\n",
    "# 定義\n",
    "def MAE(y_true, predictions):\n",
    "    y_true, predictions = np.array(y_true), np.array(predictions)\n",
    "    return np.mean(np.abs(y_true - predictions))\n",
    "\n",
    "def MSE(actual, pred): \n",
    "    actual, pred = np.array(actual), np.array(pred)\n",
    "    return np.square(np.subtract(actual,pred)).mean() \n",
    "\n",
    "def MAPE(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))\n",
    "\n",
    "# 預處理\n",
    "fliter1 = (datasetTrain[\"country\"] != ' ?')\n",
    "fliter2 = (datasetTrain[\"occupation\"] != ' ?')\n",
    "fliter3 = (datasetTrain[\"workclass\"] != ' ?')\n",
    "datasetTrain2 = datasetTrain[fliter1 & fliter2 & fliter3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b501f5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-d345d00e2f26>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  datasetTrain2['workclass'] = labelencoder.fit_transform(datasetTrain2['workclass'])\n",
      "<ipython-input-2-d345d00e2f26>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  datasetTrain2['education'] = labelencoder.fit_transform(datasetTrain2['education'])\n",
      "<ipython-input-2-d345d00e2f26>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  datasetTrain2['marital-status'] = labelencoder.fit_transform(datasetTrain2['marital-status'])\n",
      "<ipython-input-2-d345d00e2f26>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  datasetTrain2['occupation'] = labelencoder.fit_transform(datasetTrain2['occupation'])\n",
      "<ipython-input-2-d345d00e2f26>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  datasetTrain2['relationship'] = labelencoder.fit_transform(datasetTrain2['relationship'])\n",
      "<ipython-input-2-d345d00e2f26>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  datasetTrain2['race'] = labelencoder.fit_transform(datasetTrain2['race'])\n",
      "<ipython-input-2-d345d00e2f26>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  datasetTrain2['sex'] = labelencoder.fit_transform(datasetTrain2['sex'])\n",
      "<ipython-input-2-d345d00e2f26>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  datasetTrain2['country'] = labelencoder.fit_transform(datasetTrain2['country'])\n",
      "<ipython-input-2-d345d00e2f26>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  datasetTrain2['income'] = labelencoder.fit_transform(datasetTrain2['income'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>77516</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>83311</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>215646</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>234721</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>338409</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>257302</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>154374</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>151910</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>201490</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>287927</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30162 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  workclass  fnlwgt  education  education-num  marital-status  \\\n",
       "0       39          5   77516          9             13               4   \n",
       "1       50          4   83311          9             13               2   \n",
       "2       38          2  215646         11              9               0   \n",
       "3       53          2  234721          1              7               2   \n",
       "4       28          2  338409          9             13               2   \n",
       "...    ...        ...     ...        ...            ...             ...   \n",
       "32556   27          2  257302          7             12               2   \n",
       "32557   40          2  154374         11              9               2   \n",
       "32558   58          2  151910         11              9               6   \n",
       "32559   22          2  201490         11              9               4   \n",
       "32560   52          3  287927         11              9               2   \n",
       "\n",
       "       occupation  relationship  race  sex  capital-gain  capital-loss  \\\n",
       "0               0             1     4    1          2174             0   \n",
       "1               3             0     4    1             0             0   \n",
       "2               5             1     4    1             0             0   \n",
       "3               5             0     2    1             0             0   \n",
       "4               9             5     2    0             0             0   \n",
       "...           ...           ...   ...  ...           ...           ...   \n",
       "32556          12             5     4    0             0             0   \n",
       "32557           6             0     4    1             0             0   \n",
       "32558           0             4     4    0             0             0   \n",
       "32559           0             3     4    1             0             0   \n",
       "32560           3             5     4    0         15024             0   \n",
       "\n",
       "       hours-per-week  country  income  \n",
       "0                  40       38       0  \n",
       "1                  13       38       0  \n",
       "2                  40       38       0  \n",
       "3                  40       38       0  \n",
       "4                  40        4       0  \n",
       "...               ...      ...     ...  \n",
       "32556              38       38       0  \n",
       "32557              40       38       1  \n",
       "32558              40       38       0  \n",
       "32559              20       38       0  \n",
       "32560              40       38       1  \n",
       "\n",
       "[30162 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 資料數值化\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "datasetTrain2['workclass'] = labelencoder.fit_transform(datasetTrain2['workclass'])\n",
    "datasetTrain2['education'] = labelencoder.fit_transform(datasetTrain2['education'])\n",
    "datasetTrain2['marital-status'] = labelencoder.fit_transform(datasetTrain2['marital-status'])\n",
    "datasetTrain2['occupation'] = labelencoder.fit_transform(datasetTrain2['occupation'])\n",
    "datasetTrain2['relationship'] = labelencoder.fit_transform(datasetTrain2['relationship'])\n",
    "datasetTrain2['race'] = labelencoder.fit_transform(datasetTrain2['race'])\n",
    "datasetTrain2['sex'] = labelencoder.fit_transform(datasetTrain2['sex'])\n",
    "datasetTrain2['country'] = labelencoder.fit_transform(datasetTrain2['country'])\n",
    "datasetTrain2['income'] = labelencoder.fit_transform(datasetTrain2['income'])\n",
    "datasetTrain2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3895acc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.301370</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.043338</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.452055</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.047277</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.287671</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.137244</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.493151</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.150212</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.220703</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30157</th>\n",
       "      <td>0.136986</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.165563</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377551</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30158</th>\n",
       "      <td>0.315068</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.095589</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30159</th>\n",
       "      <td>0.561644</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.093914</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30160</th>\n",
       "      <td>0.068493</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.127620</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.193878</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30161</th>\n",
       "      <td>0.479452</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.186383</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30162 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  workclass    fnlwgt  education  education-num  \\\n",
       "0      0.301370   0.833333  0.043338   0.600000       0.800000   \n",
       "1      0.452055   0.666667  0.047277   0.600000       0.800000   \n",
       "2      0.287671   0.333333  0.137244   0.733333       0.533333   \n",
       "3      0.493151   0.333333  0.150212   0.066667       0.400000   \n",
       "4      0.150685   0.333333  0.220703   0.600000       0.800000   \n",
       "...         ...        ...       ...        ...            ...   \n",
       "30157  0.136986   0.333333  0.165563   0.466667       0.733333   \n",
       "30158  0.315068   0.333333  0.095589   0.733333       0.533333   \n",
       "30159  0.561644   0.333333  0.093914   0.733333       0.533333   \n",
       "30160  0.068493   0.333333  0.127620   0.733333       0.533333   \n",
       "30161  0.479452   0.500000  0.186383   0.733333       0.533333   \n",
       "\n",
       "       marital-status  occupation  relationship  race  sex  capital-gain  \\\n",
       "0            0.666667    0.000000           0.2   1.0  1.0      0.021740   \n",
       "1            0.333333    0.230769           0.0   1.0  1.0      0.000000   \n",
       "2            0.000000    0.384615           0.2   1.0  1.0      0.000000   \n",
       "3            0.333333    0.384615           0.0   0.5  1.0      0.000000   \n",
       "4            0.333333    0.692308           1.0   0.5  0.0      0.000000   \n",
       "...               ...         ...           ...   ...  ...           ...   \n",
       "30157        0.333333    0.923077           1.0   1.0  0.0      0.000000   \n",
       "30158        0.333333    0.461538           0.0   1.0  1.0      0.000000   \n",
       "30159        1.000000    0.000000           0.8   1.0  0.0      0.000000   \n",
       "30160        0.666667    0.000000           0.6   1.0  1.0      0.000000   \n",
       "30161        0.333333    0.230769           1.0   1.0  0.0      0.150242   \n",
       "\n",
       "       capital-loss  hours-per-week  country  income  \n",
       "0               0.0        0.397959     0.95     0.0  \n",
       "1               0.0        0.122449     0.95     0.0  \n",
       "2               0.0        0.397959     0.95     0.0  \n",
       "3               0.0        0.397959     0.95     0.0  \n",
       "4               0.0        0.397959     0.10     0.0  \n",
       "...             ...             ...      ...     ...  \n",
       "30157           0.0        0.377551     0.95     0.0  \n",
       "30158           0.0        0.397959     0.95     1.0  \n",
       "30159           0.0        0.397959     0.95     0.0  \n",
       "30160           0.0        0.193878     0.95     0.0  \n",
       "30161           0.0        0.397959     0.95     1.0  \n",
       "\n",
       "[30162 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 正規化\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "dataset_1 = scaler.fit_transform(datasetTrain2)\n",
    "dataset_2 = pd.DataFrame(dataset_1,columns=datasetTrain2.columns)\n",
    "dataset_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccfe710b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定答案\n",
    "dataset_target = dataset_2.pop('hours-per-week')\n",
    "dataset_target.loc()[dataset_target == 0]=0.1\n",
    "# 分割資料\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split( dataset_2 , dataset_target , test_size = 0.2, random_state = 0)\n",
    "X_train.to_csv(\"fgeygfyue.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f2f8cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                480       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                170       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,189\n",
      "Trainable params: 1,189\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#建立Sequential物件\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "network.add(layers.Dense(16, activation='relu'))\n",
    "network.add(layers.Dense(10, activation='relu'))\n",
    "#輸出層，Sigmoid\n",
    "network.add(layers.Dense(1))\n",
    "network.add(Flatten())\n",
    "network.compile(optimizer='sgd', loss='MAE',metrics=[tf.keras.metrics.mae,tf.keras.metrics.mape,tf.metrics.mse] )\n",
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d50b46fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "483/483 [==============================] - 0s 590us/step - loss: 0.0837 - mean_absolute_error: 0.0837 - mean_absolute_percentage_error: 33.7084 - mean_squared_error: 0.0148\n",
      "Epoch 2/50\n",
      "483/483 [==============================] - 0s 672us/step - loss: 0.0767 - mean_absolute_error: 0.0767 - mean_absolute_percentage_error: 32.2563 - mean_squared_error: 0.0139\n",
      "Epoch 3/50\n",
      "483/483 [==============================] - 0s 550us/step - loss: 0.0758 - mean_absolute_error: 0.0758 - mean_absolute_percentage_error: 31.9790 - mean_squared_error: 0.0139\n",
      "Epoch 4/50\n",
      "483/483 [==============================] - 0s 563us/step - loss: 0.0752 - mean_absolute_error: 0.0752 - mean_absolute_percentage_error: 31.7897 - mean_squared_error: 0.0139\n",
      "Epoch 5/50\n",
      "483/483 [==============================] - 0s 573us/step - loss: 0.0749 - mean_absolute_error: 0.0749 - mean_absolute_percentage_error: 31.6700 - mean_squared_error: 0.0139\n",
      "Epoch 6/50\n",
      "483/483 [==============================] - 0s 604us/step - loss: 0.0748 - mean_absolute_error: 0.0748 - mean_absolute_percentage_error: 31.5938 - mean_squared_error: 0.0139\n",
      "Epoch 7/50\n",
      "483/483 [==============================] - 0s 565us/step - loss: 0.0745 - mean_absolute_error: 0.0745 - mean_absolute_percentage_error: 31.5385 - mean_squared_error: 0.0139\n",
      "Epoch 8/50\n",
      "483/483 [==============================] - 0s 560us/step - loss: 0.0743 - mean_absolute_error: 0.0743 - mean_absolute_percentage_error: 31.4732 - mean_squared_error: 0.0139\n",
      "Epoch 9/50\n",
      "483/483 [==============================] - 0s 585us/step - loss: 0.0742 - mean_absolute_error: 0.0742 - mean_absolute_percentage_error: 31.4365 - mean_squared_error: 0.0139\n",
      "Epoch 10/50\n",
      "483/483 [==============================] - 0s 559us/step - loss: 0.0741 - mean_absolute_error: 0.0741 - mean_absolute_percentage_error: 31.4167 - mean_squared_error: 0.0139\n",
      "Epoch 11/50\n",
      "483/483 [==============================] - 0s 585us/step - loss: 0.0740 - mean_absolute_error: 0.0740 - mean_absolute_percentage_error: 31.3857 - mean_squared_error: 0.0138\n",
      "Epoch 12/50\n",
      "483/483 [==============================] - 0s 569us/step - loss: 0.0739 - mean_absolute_error: 0.0739 - mean_absolute_percentage_error: 31.3863 - mean_squared_error: 0.0138\n",
      "Epoch 13/50\n",
      "483/483 [==============================] - 0s 556us/step - loss: 0.0739 - mean_absolute_error: 0.0739 - mean_absolute_percentage_error: 31.3775 - mean_squared_error: 0.0138\n",
      "Epoch 14/50\n",
      "483/483 [==============================] - 0s 597us/step - loss: 0.0738 - mean_absolute_error: 0.0738 - mean_absolute_percentage_error: 31.3576 - mean_squared_error: 0.0139\n",
      "Epoch 15/50\n",
      "483/483 [==============================] - 0s 593us/step - loss: 0.0737 - mean_absolute_error: 0.0737 - mean_absolute_percentage_error: 31.3334 - mean_squared_error: 0.0138\n",
      "Epoch 16/50\n",
      "483/483 [==============================] - 0s 627us/step - loss: 0.0737 - mean_absolute_error: 0.0737 - mean_absolute_percentage_error: 31.3549 - mean_squared_error: 0.0138\n",
      "Epoch 17/50\n",
      "483/483 [==============================] - 0s 696us/step - loss: 0.0737 - mean_absolute_error: 0.0737 - mean_absolute_percentage_error: 31.3440 - mean_squared_error: 0.0138\n",
      "Epoch 18/50\n",
      "483/483 [==============================] - 0s 699us/step - loss: 0.0737 - mean_absolute_error: 0.0737 - mean_absolute_percentage_error: 31.3968 - mean_squared_error: 0.0139\n",
      "Epoch 19/50\n",
      "483/483 [==============================] - 0s 652us/step - loss: 0.0736 - mean_absolute_error: 0.0736 - mean_absolute_percentage_error: 31.3142 - mean_squared_error: 0.0138\n",
      "Epoch 20/50\n",
      "483/483 [==============================] - 0s 876us/step - loss: 0.0736 - mean_absolute_error: 0.0736 - mean_absolute_percentage_error: 31.3478 - mean_squared_error: 0.0139\n",
      "Epoch 21/50\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.0736 - mean_absolute_error: 0.0736 - mean_absolute_percentage_error: 31.3232 - mean_squared_error: 0.0138\n",
      "Epoch 22/50\n",
      "483/483 [==============================] - 0s 1ms/step - loss: 0.0735 - mean_absolute_error: 0.0735 - mean_absolute_percentage_error: 31.3195 - mean_squared_error: 0.0138\n",
      "Epoch 23/50\n",
      "483/483 [==============================] - 0s 833us/step - loss: 0.0735 - mean_absolute_error: 0.0735 - mean_absolute_percentage_error: 31.3039 - mean_squared_error: 0.0138\n",
      "Epoch 24/50\n",
      "483/483 [==============================] - 0s 938us/step - loss: 0.0735 - mean_absolute_error: 0.0735 - mean_absolute_percentage_error: 31.3138 - mean_squared_error: 0.0138\n",
      "Epoch 25/50\n",
      "483/483 [==============================] - 0s 868us/step - loss: 0.0735 - mean_absolute_error: 0.0735 - mean_absolute_percentage_error: 31.3169 - mean_squared_error: 0.0138\n",
      "Epoch 26/50\n",
      "483/483 [==============================] - 0s 891us/step - loss: 0.0734 - mean_absolute_error: 0.0734 - mean_absolute_percentage_error: 31.3350 - mean_squared_error: 0.0138\n",
      "Epoch 27/50\n",
      "483/483 [==============================] - 0s 1ms/step - loss: 0.0733 - mean_absolute_error: 0.0733 - mean_absolute_percentage_error: 31.3029 - mean_squared_error: 0.0138\n",
      "Epoch 28/50\n",
      "483/483 [==============================] - 0s 1ms/step - loss: 0.0734 - mean_absolute_error: 0.0734 - mean_absolute_percentage_error: 31.3391 - mean_squared_error: 0.0138\n",
      "Epoch 29/50\n",
      "483/483 [==============================] - 0s 905us/step - loss: 0.0734 - mean_absolute_error: 0.0734 - mean_absolute_percentage_error: 31.3246 - mean_squared_error: 0.0138\n",
      "Epoch 30/50\n",
      "483/483 [==============================] - 0s 971us/step - loss: 0.0733 - mean_absolute_error: 0.0733 - mean_absolute_percentage_error: 31.2932 - mean_squared_error: 0.0138\n",
      "Epoch 31/50\n",
      "483/483 [==============================] - 0s 1ms/step - loss: 0.0733 - mean_absolute_error: 0.0733 - mean_absolute_percentage_error: 31.2849 - mean_squared_error: 0.0138\n",
      "Epoch 32/50\n",
      "483/483 [==============================] - 0s 973us/step - loss: 0.0733 - mean_absolute_error: 0.0733 - mean_absolute_percentage_error: 31.3290 - mean_squared_error: 0.0138\n",
      "Epoch 33/50\n",
      "483/483 [==============================] - 0s 747us/step - loss: 0.0733 - mean_absolute_error: 0.0733 - mean_absolute_percentage_error: 31.3134 - mean_squared_error: 0.0138\n",
      "Epoch 34/50\n",
      "483/483 [==============================] - 0s 655us/step - loss: 0.0733 - mean_absolute_error: 0.0733 - mean_absolute_percentage_error: 31.3207 - mean_squared_error: 0.0138\n",
      "Epoch 35/50\n",
      "483/483 [==============================] - 0s 625us/step - loss: 0.0733 - mean_absolute_error: 0.0733 - mean_absolute_percentage_error: 31.3071 - mean_squared_error: 0.0138\n",
      "Epoch 36/50\n",
      "483/483 [==============================] - 0s 566us/step - loss: 0.0732 - mean_absolute_error: 0.0732 - mean_absolute_percentage_error: 31.2701 - mean_squared_error: 0.0138\n",
      "Epoch 37/50\n",
      "483/483 [==============================] - 0s 586us/step - loss: 0.0733 - mean_absolute_error: 0.0733 - mean_absolute_percentage_error: 31.3556 - mean_squared_error: 0.0138\n",
      "Epoch 38/50\n",
      "483/483 [==============================] - 0s 562us/step - loss: 0.0733 - mean_absolute_error: 0.0733 - mean_absolute_percentage_error: 31.3196 - mean_squared_error: 0.0138\n",
      "Epoch 39/50\n",
      "483/483 [==============================] - 0s 587us/step - loss: 0.0731 - mean_absolute_error: 0.0731 - mean_absolute_percentage_error: 31.2730 - mean_squared_error: 0.0138\n",
      "Epoch 40/50\n",
      "483/483 [==============================] - 0s 590us/step - loss: 0.0731 - mean_absolute_error: 0.0731 - mean_absolute_percentage_error: 31.2748 - mean_squared_error: 0.0138\n",
      "Epoch 41/50\n",
      "483/483 [==============================] - 0s 564us/step - loss: 0.0732 - mean_absolute_error: 0.0732 - mean_absolute_percentage_error: 31.3231 - mean_squared_error: 0.0138\n",
      "Epoch 42/50\n",
      "483/483 [==============================] - 0s 590us/step - loss: 0.0732 - mean_absolute_error: 0.0732 - mean_absolute_percentage_error: 31.2859 - mean_squared_error: 0.0138\n",
      "Epoch 43/50\n",
      "483/483 [==============================] - 0s 556us/step - loss: 0.0731 - mean_absolute_error: 0.0731 - mean_absolute_percentage_error: 31.2644 - mean_squared_error: 0.0138\n",
      "Epoch 44/50\n",
      "483/483 [==============================] - 0s 560us/step - loss: 0.0731 - mean_absolute_error: 0.0731 - mean_absolute_percentage_error: 31.2788 - mean_squared_error: 0.0138\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "483/483 [==============================] - 0s 610us/step - loss: 0.0730 - mean_absolute_error: 0.0730 - mean_absolute_percentage_error: 31.2614 - mean_squared_error: 0.0138\n",
      "Epoch 46/50\n",
      "483/483 [==============================] - 0s 589us/step - loss: 0.0731 - mean_absolute_error: 0.0731 - mean_absolute_percentage_error: 31.2910 - mean_squared_error: 0.0138\n",
      "Epoch 47/50\n",
      "483/483 [==============================] - 0s 532us/step - loss: 0.0731 - mean_absolute_error: 0.0731 - mean_absolute_percentage_error: 31.2850 - mean_squared_error: 0.0138\n",
      "Epoch 48/50\n",
      "483/483 [==============================] - 0s 571us/step - loss: 0.0731 - mean_absolute_error: 0.0731 - mean_absolute_percentage_error: 31.2827 - mean_squared_error: 0.0138\n",
      "Epoch 49/50\n",
      "483/483 [==============================] - 0s 585us/step - loss: 0.0730 - mean_absolute_error: 0.0730 - mean_absolute_percentage_error: 31.2538 - mean_squared_error: 0.0138\n",
      "Epoch 50/50\n",
      "483/483 [==============================] - 0s 566us/step - loss: 0.0730 - mean_absolute_error: 0.0730 - mean_absolute_percentage_error: 31.2667 - mean_squared_error: 0.0138\n"
     ]
    }
   ],
   "source": [
    "history = network.fit(X_train,Y_train,\n",
    "epochs=50,\n",
    "batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a79111",
   "metadata": {},
   "source": [
    "# 測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75a181d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 匯入adult.test做測試\n",
    "datasetTest = pd.read_csv('adult.test.csv')\n",
    "fliter1 = (datasetTest[\"country\"] != ' ?')\n",
    "fliter2 = (datasetTest[\"occupation\"] != ' ?')\n",
    "fliter3 = (datasetTest[\"workclass\"] != ' ?')\n",
    "datasetTest2 = datasetTest[fliter1 & fliter2 & fliter3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1499a5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-e096b4b273b3>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  datasetTest2['workclass'] = labelencoder.fit_transform(datasetTest2['workclass'])\n",
      "<ipython-input-8-e096b4b273b3>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  datasetTest2['education'] = labelencoder.fit_transform(datasetTest2['education'])\n",
      "<ipython-input-8-e096b4b273b3>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  datasetTest2['marital-status'] = labelencoder.fit_transform(datasetTest2['marital-status'])\n",
      "<ipython-input-8-e096b4b273b3>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  datasetTest2['occupation'] = labelencoder.fit_transform(datasetTest2['occupation'])\n",
      "<ipython-input-8-e096b4b273b3>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  datasetTest2['relationship'] = labelencoder.fit_transform(datasetTest2['relationship'])\n",
      "<ipython-input-8-e096b4b273b3>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  datasetTest2['race'] = labelencoder.fit_transform(datasetTest2['race'])\n",
      "<ipython-input-8-e096b4b273b3>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  datasetTest2['sex'] = labelencoder.fit_transform(datasetTest2['sex'])\n",
      "<ipython-input-8-e096b4b273b3>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  datasetTest2['country'] = labelencoder.fit_transform(datasetTest2['country'])\n",
      "<ipython-input-8-e096b4b273b3>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  datasetTest2['income'] = labelencoder.fit_transform(datasetTest2['income'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>226802</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>89814</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>336951</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>160323</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>198693</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16275</th>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>245211</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16276</th>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>215419</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16278</th>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>374983</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16279</th>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>83891</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5455</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16280</th>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>182148</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15060 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  workclass  fnlwgt  education  education-num  marital-status  \\\n",
       "0       25          2  226802          1              7               4   \n",
       "1       38          2   89814         11              9               2   \n",
       "2       28          1  336951          7             12               2   \n",
       "3       44          2  160323         15             10               2   \n",
       "5       34          2  198693          0              6               4   \n",
       "...    ...        ...     ...        ...            ...             ...   \n",
       "16275   33          2  245211          9             13               4   \n",
       "16276   39          2  215419          9             13               0   \n",
       "16278   38          2  374983          9             13               2   \n",
       "16279   44          2   83891          9             13               0   \n",
       "16280   35          3  182148          9             13               2   \n",
       "\n",
       "       occupation  relationship  race  sex  capital-gain  capital-loss  \\\n",
       "0               6             3     2    1             0             0   \n",
       "1               4             0     4    1             0             0   \n",
       "2              10             0     4    1             0             0   \n",
       "3               6             0     2    1          7688             0   \n",
       "5               7             1     4    1             0             0   \n",
       "...           ...           ...   ...  ...           ...           ...   \n",
       "16275           9             3     4    1             0             0   \n",
       "16276           9             1     4    0             0             0   \n",
       "16278           9             0     4    1             0             0   \n",
       "16279           0             3     1    1          5455             0   \n",
       "16280           3             0     4    1             0             0   \n",
       "\n",
       "       hours-per-week  country  income  \n",
       "0                  40       37       0  \n",
       "1                  50       37       0  \n",
       "2                  40       37       1  \n",
       "3                  40       37       1  \n",
       "5                  30       37       0  \n",
       "...               ...      ...     ...  \n",
       "16275              40       37       0  \n",
       "16276              36       37       0  \n",
       "16278              50       37       0  \n",
       "16279              40       37       0  \n",
       "16280              60       37       1  \n",
       "\n",
       "[15060 rows x 15 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 資料數值化\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "datasetTest2['workclass'] = labelencoder.fit_transform(datasetTest2['workclass'])\n",
    "datasetTest2['education'] = labelencoder.fit_transform(datasetTest2['education'])\n",
    "datasetTest2['marital-status'] = labelencoder.fit_transform(datasetTest2['marital-status'])\n",
    "datasetTest2['occupation'] = labelencoder.fit_transform(datasetTest2['occupation'])\n",
    "datasetTest2['relationship'] = labelencoder.fit_transform(datasetTest2['relationship'])\n",
    "datasetTest2['race'] = labelencoder.fit_transform(datasetTest2['race'])\n",
    "datasetTest2['sex'] = labelencoder.fit_transform(datasetTest2['sex'])\n",
    "datasetTest2['country'] = labelencoder.fit_transform(datasetTest2['country'])\n",
    "datasetTest2['income'] = labelencoder.fit_transform(datasetTest2['income'])\n",
    "datasetTest2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfc32cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正規化\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "dataset_1 = scaler.fit_transform(datasetTrain2)\n",
    "dataset_2 = pd.DataFrame(dataset_1,columns=datasetTrain2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ee45828",
   "metadata": {},
   "outputs": [],
   "source": [
    "Testdata = dataset_2.drop(\"hours-per-week\",1)\n",
    "Truedata = dataset_2[\"hours-per-week\"]\n",
    "Y_predicted = network.predict(Testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e999606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.397959\n",
       "1        0.122449\n",
       "2        0.397959\n",
       "3        0.397959\n",
       "4        0.397959\n",
       "           ...   \n",
       "30157    0.377551\n",
       "30158    0.397959\n",
       "30159    0.397959\n",
       "30160    0.193878\n",
       "30161    0.397959\n",
       "Name: hours-per-week, Length: 30162, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Truedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "519a83e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "AVRvalue = pd.DataFrame(Truedata).mean()\n",
    "Truedata.loc()[Truedata == 0] = AVRvalue[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1d0045b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "604/604 [==============================] - 0s 581us/step - loss: 0.0733 - mean_absolute_error: 0.0733 - mean_absolute_percentage_error: 31.3389 - mean_squared_error: 0.0139\n",
      "Epoch 2/50\n",
      "604/604 [==============================] - 0s 597us/step - loss: 0.0733 - mean_absolute_error: 0.0733 - mean_absolute_percentage_error: 31.3135 - mean_squared_error: 0.0139\n",
      "Epoch 3/50\n",
      "604/604 [==============================] - 0s 567us/step - loss: 0.0732 - mean_absolute_error: 0.0732 - mean_absolute_percentage_error: 31.2801 - mean_squared_error: 0.0139\n",
      "Epoch 4/50\n",
      "604/604 [==============================] - 0s 561us/step - loss: 0.0732 - mean_absolute_error: 0.0732 - mean_absolute_percentage_error: 31.3109 - mean_squared_error: 0.0139\n",
      "Epoch 5/50\n",
      "604/604 [==============================] - 0s 539us/step - loss: 0.0733 - mean_absolute_error: 0.0733 - mean_absolute_percentage_error: 31.3030 - mean_squared_error: 0.0139\n",
      "Epoch 6/50\n",
      "604/604 [==============================] - 0s 599us/step - loss: 0.0732 - mean_absolute_error: 0.0732 - mean_absolute_percentage_error: 31.3078 - mean_squared_error: 0.0139\n",
      "Epoch 7/50\n",
      "604/604 [==============================] - 0s 548us/step - loss: 0.0732 - mean_absolute_error: 0.0732 - mean_absolute_percentage_error: 31.3293 - mean_squared_error: 0.0139\n",
      "Epoch 8/50\n",
      "604/604 [==============================] - 0s 526us/step - loss: 0.0732 - mean_absolute_error: 0.0732 - mean_absolute_percentage_error: 31.2984 - mean_squared_error: 0.0139\n",
      "Epoch 9/50\n",
      "604/604 [==============================] - 0s 571us/step - loss: 0.0732 - mean_absolute_error: 0.0732 - mean_absolute_percentage_error: 31.3011 - mean_squared_error: 0.0139\n",
      "Epoch 10/50\n",
      "604/604 [==============================] - 0s 604us/step - loss: 0.0731 - mean_absolute_error: 0.0731 - mean_absolute_percentage_error: 31.2882 - mean_squared_error: 0.0139\n",
      "Epoch 11/50\n",
      "604/604 [==============================] - 0s 607us/step - loss: 0.0731 - mean_absolute_error: 0.0731 - mean_absolute_percentage_error: 31.2893 - mean_squared_error: 0.0139\n",
      "Epoch 12/50\n",
      "604/604 [==============================] - 0s 555us/step - loss: 0.0731 - mean_absolute_error: 0.0731 - mean_absolute_percentage_error: 31.2928 - mean_squared_error: 0.0139\n",
      "Epoch 13/50\n",
      "604/604 [==============================] - 0s 795us/step - loss: 0.0731 - mean_absolute_error: 0.0731 - mean_absolute_percentage_error: 31.3084 - mean_squared_error: 0.0139\n",
      "Epoch 14/50\n",
      "604/604 [==============================] - 1s 913us/step - loss: 0.0731 - mean_absolute_error: 0.0731 - mean_absolute_percentage_error: 31.2823 - mean_squared_error: 0.0139\n",
      "Epoch 15/50\n",
      "604/604 [==============================] - 0s 787us/step - loss: 0.0731 - mean_absolute_error: 0.0731 - mean_absolute_percentage_error: 31.2874 - mean_squared_error: 0.0139\n",
      "Epoch 16/50\n",
      "604/604 [==============================] - 0s 795us/step - loss: 0.0731 - mean_absolute_error: 0.0731 - mean_absolute_percentage_error: 31.2811 - mean_squared_error: 0.0139\n",
      "Epoch 17/50\n",
      "604/604 [==============================] - 0s 773us/step - loss: 0.0731 - mean_absolute_error: 0.0731 - mean_absolute_percentage_error: 31.2833 - mean_squared_error: 0.0139\n",
      "Epoch 18/50\n",
      "604/604 [==============================] - 0s 778us/step - loss: 0.0731 - mean_absolute_error: 0.0731 - mean_absolute_percentage_error: 31.2611 - mean_squared_error: 0.0139\n",
      "Epoch 19/50\n",
      "604/604 [==============================] - 0s 809us/step - loss: 0.0730 - mean_absolute_error: 0.0730 - mean_absolute_percentage_error: 31.2675 - mean_squared_error: 0.0139\n",
      "Epoch 20/50\n",
      "604/604 [==============================] - 0s 799us/step - loss: 0.0731 - mean_absolute_error: 0.0731 - mean_absolute_percentage_error: 31.2930 - mean_squared_error: 0.0139\n",
      "Epoch 21/50\n",
      "604/604 [==============================] - 0s 789us/step - loss: 0.0730 - mean_absolute_error: 0.0730 - mean_absolute_percentage_error: 31.2663 - mean_squared_error: 0.0139\n",
      "Epoch 22/50\n",
      "604/604 [==============================] - 0s 805us/step - loss: 0.0730 - mean_absolute_error: 0.0730 - mean_absolute_percentage_error: 31.2646 - mean_squared_error: 0.0139\n",
      "Epoch 23/50\n",
      "604/604 [==============================] - 0s 807us/step - loss: 0.0730 - mean_absolute_error: 0.0730 - mean_absolute_percentage_error: 31.2492 - mean_squared_error: 0.0139\n",
      "Epoch 24/50\n",
      "604/604 [==============================] - 0s 785us/step - loss: 0.0730 - mean_absolute_error: 0.0730 - mean_absolute_percentage_error: 31.2742 - mean_squared_error: 0.0139\n",
      "Epoch 25/50\n",
      "604/604 [==============================] - 0s 716us/step - loss: 0.0730 - mean_absolute_error: 0.0730 - mean_absolute_percentage_error: 31.2404 - mean_squared_error: 0.0138\n",
      "Epoch 26/50\n",
      "604/604 [==============================] - 0s 577us/step - loss: 0.0729 - mean_absolute_error: 0.0729 - mean_absolute_percentage_error: 31.2337 - mean_squared_error: 0.0139\n",
      "Epoch 27/50\n",
      "604/604 [==============================] - 0s 656us/step - loss: 0.0730 - mean_absolute_error: 0.0730 - mean_absolute_percentage_error: 31.2555 - mean_squared_error: 0.0139\n",
      "Epoch 28/50\n",
      "604/604 [==============================] - 0s 656us/step - loss: 0.0729 - mean_absolute_error: 0.0729 - mean_absolute_percentage_error: 31.2449 - mean_squared_error: 0.0138\n",
      "Epoch 29/50\n",
      "604/604 [==============================] - 0s 767us/step - loss: 0.0730 - mean_absolute_error: 0.0730 - mean_absolute_percentage_error: 31.2491 - mean_squared_error: 0.0139\n",
      "Epoch 30/50\n",
      "604/604 [==============================] - 0s 618us/step - loss: 0.0729 - mean_absolute_error: 0.0729 - mean_absolute_percentage_error: 31.2483 - mean_squared_error: 0.0139\n",
      "Epoch 31/50\n",
      "604/604 [==============================] - 0s 655us/step - loss: 0.0729 - mean_absolute_error: 0.0729 - mean_absolute_percentage_error: 31.2127 - mean_squared_error: 0.0139\n",
      "Epoch 32/50\n",
      "604/604 [==============================] - 0s 669us/step - loss: 0.0729 - mean_absolute_error: 0.0729 - mean_absolute_percentage_error: 31.2424 - mean_squared_error: 0.0138\n",
      "Epoch 33/50\n",
      "604/604 [==============================] - 0s 677us/step - loss: 0.0729 - mean_absolute_error: 0.0729 - mean_absolute_percentage_error: 31.2092 - mean_squared_error: 0.0138\n",
      "Epoch 34/50\n",
      "604/604 [==============================] - 0s 715us/step - loss: 0.0729 - mean_absolute_error: 0.0729 - mean_absolute_percentage_error: 31.2370 - mean_squared_error: 0.0139\n",
      "Epoch 35/50\n",
      "604/604 [==============================] - 0s 686us/step - loss: 0.0729 - mean_absolute_error: 0.0729 - mean_absolute_percentage_error: 31.2395 - mean_squared_error: 0.0139\n",
      "Epoch 36/50\n",
      "604/604 [==============================] - 0s 671us/step - loss: 0.0729 - mean_absolute_error: 0.0729 - mean_absolute_percentage_error: 31.2273 - mean_squared_error: 0.0138\n",
      "Epoch 37/50\n",
      "604/604 [==============================] - 0s 629us/step - loss: 0.0729 - mean_absolute_error: 0.0729 - mean_absolute_percentage_error: 31.2322 - mean_squared_error: 0.0138\n",
      "Epoch 38/50\n",
      "604/604 [==============================] - 0s 704us/step - loss: 0.0728 - mean_absolute_error: 0.0728 - mean_absolute_percentage_error: 31.1974 - mean_squared_error: 0.0138\n",
      "Epoch 39/50\n",
      "604/604 [==============================] - 0s 714us/step - loss: 0.0728 - mean_absolute_error: 0.0728 - mean_absolute_percentage_error: 31.1923 - mean_squared_error: 0.0138\n",
      "Epoch 40/50\n",
      "604/604 [==============================] - 0s 659us/step - loss: 0.0728 - mean_absolute_error: 0.0728 - mean_absolute_percentage_error: 31.2209 - mean_squared_error: 0.0138\n",
      "Epoch 41/50\n",
      "604/604 [==============================] - 0s 691us/step - loss: 0.0728 - mean_absolute_error: 0.0728 - mean_absolute_percentage_error: 31.1736 - mean_squared_error: 0.0138\n",
      "Epoch 42/50\n",
      "604/604 [==============================] - 0s 671us/step - loss: 0.0728 - mean_absolute_error: 0.0728 - mean_absolute_percentage_error: 31.1999 - mean_squared_error: 0.0138\n",
      "Epoch 43/50\n",
      "604/604 [==============================] - 0s 727us/step - loss: 0.0728 - mean_absolute_error: 0.0728 - mean_absolute_percentage_error: 31.1954 - mean_squared_error: 0.0138\n",
      "Epoch 44/50\n",
      "604/604 [==============================] - 0s 645us/step - loss: 0.0728 - mean_absolute_error: 0.0728 - mean_absolute_percentage_error: 31.1919 - mean_squared_error: 0.0138\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "604/604 [==============================] - 0s 603us/step - loss: 0.0728 - mean_absolute_error: 0.0728 - mean_absolute_percentage_error: 31.1819 - mean_squared_error: 0.0138\n",
      "Epoch 46/50\n",
      "604/604 [==============================] - 0s 581us/step - loss: 0.0727 - mean_absolute_error: 0.0727 - mean_absolute_percentage_error: 31.1662 - mean_squared_error: 0.0138\n",
      "Epoch 47/50\n",
      "604/604 [==============================] - 0s 686us/step - loss: 0.0727 - mean_absolute_error: 0.0727 - mean_absolute_percentage_error: 31.1705 - mean_squared_error: 0.0138\n",
      "Epoch 48/50\n",
      "604/604 [==============================] - 0s 653us/step - loss: 0.0728 - mean_absolute_error: 0.0728 - mean_absolute_percentage_error: 31.1721 - mean_squared_error: 0.0138\n",
      "Epoch 49/50\n",
      "604/604 [==============================] - 0s 615us/step - loss: 0.0728 - mean_absolute_error: 0.0728 - mean_absolute_percentage_error: 31.1666 - mean_squared_error: 0.0138\n",
      "Epoch 50/50\n",
      "604/604 [==============================] - 0s 733us/step - loss: 0.0727 - mean_absolute_error: 0.0727 - mean_absolute_percentage_error: 31.1664 - mean_squared_error: 0.0138\n"
     ]
    }
   ],
   "source": [
    "history = network.fit(Testdata,Truedata\n",
    "                      ,epochs=50\n",
    "                      ,batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7179b3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error #MSE\n",
    "from sklearn.metrics import mean_absolute_error #MAE\n",
    "from sklearn.metrics import mean_absolute_percentage_error #MAPE\n",
    "mse = mean_squared_error(Truedata, Y_predicted)\n",
    "mae = mean_absolute_error(Truedata, Y_predicted)\n",
    "mape=mean_absolute_percentage_error(Truedata, Y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d88800fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01393757474306556 0.07309398507985683 0.3103230652037647\n"
     ]
    }
   ],
   "source": [
    "print(mse,\n",
    "     mae,\n",
    "     mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08ae57c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#輸出圖表\n",
    "history.history['mean_absolute_percentage_error']=list(map(lambda x:x/100, history.history['mean_absolute_percentage_error']))\n",
    "pd.DataFrame(history.history).plot(figsize = (8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02afc4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
